# üéØ Exerc√≠cio Pr√°tico: Qualidade de Dados com PySpark

**MBA Engenharia de Dados - Avalia√ß√£o Pr√°tica**

---

## üìã Contexto do Exerc√≠cio

Voc√™ foi contratado como **Engenheiro de Dados** pela empresa **TechCommerce**, um e-commerce em crescimento. A empresa est√° enfrentando s√©rios problemas de qualidade em sua base de dados de clientes e vendas, impactando:

- üìä Relat√≥rios gerenciais incorretos
- üìß Campanhas de marketing falhando
- üöö Entregas em endere√ßos errados
- üí∞ Perda de receita estimada em R$ 2M/ano

**Sua miss√£o:** Implementar um sistema de monitoramento e corre√ß√£o de qualidade de dados usando PySpark.

---

## üéØ Objetivos de Aprendizagem

Ao final deste exerc√≠cio, voc√™ ser√° capaz de:

1. ‚úÖ Implementar as 6 dimens√µes de qualidade de dados
2. ‚úÖ Calcular KQIs (Key Quality Indicators) 
3. ‚úÖ Criar dashboards de monitoramento
4. ‚úÖ Aplicar t√©cnicas de data cleansing
5. ‚úÖ Gerar relat√≥rios executivos de qualidade

---

## üìä Dataset Fornecido

Voc√™ receber√° um arquivo CSV com dados de clientes e vendas contendo os seguintes problemas intencionais:

```
clientes_vendas.csv
‚îú‚îÄ‚îÄ id_cliente (int)
‚îú‚îÄ‚îÄ nome_completo (string)
‚îú‚îÄ‚îÄ email (string) 
‚îú‚îÄ‚îÄ telefone (string)
‚îú‚îÄ‚îÄ cpf (string)
‚îú‚îÄ‚îÄ data_nascimento (string)
‚îú‚îÄ‚îÄ endereco (string)
‚îú‚îÄ‚îÄ cidade (string)
‚îú‚îÄ‚îÄ estado (string)
‚îú‚îÄ‚îÄ cep (string)
‚îú‚îÄ‚îÄ data_cadastro (string)
‚îú‚îÄ‚îÄ status_cliente (string)
‚îú‚îÄ‚îÄ valor_ultima_compra (double)
‚îú‚îÄ‚îÄ data_ultima_compra (string)
‚îî‚îÄ‚îÄ categoria_cliente (string)
```

---

## üöÄ Parte 1: An√°lise Explorat√≥ria (25 pontos)

### 1.1 Setup Inicial (5 pontos)
```python
# TODO: Configurar SparkSession com as configura√ß√µes adequadas
# TODO: Carregar o dataset CSV
# TODO: Exibir schema e primeiras linhas
```

### 1.2 Data Profiling B√°sico (10 pontos)
Implemente fun√ß√µes para calcular:
- Total de registros
- N√∫mero de colunas
- Tipos de dados por coluna
- Estat√≠sticas b√°sicas (count, mean, std, min, max) para colunas num√©ricas

### 1.3 Identifica√ß√£o de Problemas (10 pontos)
Crie um relat√≥rio inicial identificando:
- Campos com valores nulos
- Poss√≠veis duplicatas
- Valores fora do padr√£o esperado
- Inconsist√™ncias √≥bvias

---

## üîç Parte 2: Implementa√ß√£o das Dimens√µes de DQ (40 pontos)

### 2.1 Completude (8 pontos)
```python
def analisar_completude(df):
    """
    TODO: Implementar an√°lise de completude
    - Calcular % de preenchimento por coluna
    - Identificar campos cr√≠ticos com alta taxa de nulos
    - Retornar DataFrame com resultados
    """
    pass
```

### 2.2 Validade (8 pontos)
```python
def validar_formatos(df):
    """
    TODO: Implementar valida√ß√µes de formato
    - Email: formato v√°lido
    - CPF: 11 d√≠gitos e algoritmo de valida√ß√£o
    - Telefone: 10-11 d√≠gitos
    - CEP: 8 d√≠gitos no formato XXXXX-XXX
    - Data: formato v√°lido e n√£o no futuro
    """
    pass
```

### 2.3 Unicidade (8 pontos)
```python
def analisar_duplicatas(df):
    """
    TODO: Detectar duplicatas
    - Por ID (chave prim√°ria)
    - Por CPF (identificador √∫nico)
    - Por combina√ß√£o nome + data_nascimento
    - Calcular taxa de duplica√ß√£o
    """
    pass
```

### 2.4 Consist√™ncia (8 pontos)
```python
def verificar_consistencia(df):
    """
    TODO: Verificar consist√™ncia entre campos
    - data_ultima_compra >= data_cadastro
    - status_cliente vs valor_ultima_compra
    - cidade vs estado (usar lista de refer√™ncia)
    - categoria_cliente vs valor_ultima_compra
    """
    pass
```

### 2.5 Acur√°cia (8 pontos)
```python
def detectar_anomalias(df):
    """
    TODO: Detectar poss√≠veis problemas de acur√°cia
    - Nomes com caracteres especiais ou n√∫meros
    - Idades imposs√≠veis (< 16 ou > 120 anos)
    - Valores de compra outliers (Z-score > 3)
    - CEPs inexistentes (usar faixas v√°lidas)
    """
    pass
```

---

## üìà Parte 3: KQIs e Dashboard (20 pontos)

### 3.1 C√°lculo de KQIs (10 pontos)
Implemente o c√°lculo dos seguintes indicadores:

| KQI | Meta | F√≥rmula |
|-----|------|---------|
| **Completude Geral** | >95% | (Campos preenchidos / Total campos) * 100 |
| **Taxa de Emails V√°lidos** | >98% | (Emails v√°lidos / Total emails) * 100 |
| **Taxa de Duplica√ß√£o** | <2% | (Registros duplicados / Total) * 100 |
| **Consist√™ncia Temporal** | >99% | (Datas consistentes / Total) * 100 |
| **Acur√°cia de CPF** | >95% | (CPFs v√°lidos / Total CPFs) * 100 |

### 3.2 Dashboard Visual (10 pontos)
```python
def gerar_dashboard_qualidade(kqis):
    """
    TODO: Criar dashboard visual
    - Exibir KQIs com status (üü¢üü°üî¥)
    - Calcular score geral de qualidade
    - Mostrar tend√™ncia (melhorou/piorou)
    - Destacar KQIs cr√≠ticos
    """
    pass
```

---

## üßπ Parte 4: Data Cleansing (15 pontos)

### 4.1 Estrat√©gia de Limpeza (5 pontos)
Defina e documente sua estrat√©gia:
- Quais registros ser√£o removidos?
- Quais campos ser√£o corrigidos automaticamente?
- Quais problemas precisam de interven√ß√£o manual?

### 4.2 Implementa√ß√£o da Limpeza (10 pontos)
```python
def aplicar_limpeza(df):
    """
    TODO: Implementar limpeza automatizada
    - Remover duplicatas mantendo o mais recente
    - Padronizar formatos (telefone, CEP)
    - Corrigir espa√ßos extras em nomes
    - Filtrar registros com problemas cr√≠ticos
    - Aplicar regras de neg√≥cio
    """
    pass
```

---

## üìä Entreg√°veis Esperados

### 1. Notebook Jupyter (.ipynb)
- C√≥digo completo e execut√°vel
- Coment√°rios explicativos
- Resultados das an√°lises

### 2. Relat√≥rio Executivo (.md)
```markdown
# Relat√≥rio de Qualidade de Dados - TechCommerce

## Resumo Executivo
- Score geral de qualidade: X%
- Principais problemas identificados
- Impacto estimado no neg√≥cio

## KQIs Atuais vs Metas
[Tabela com resultados]

## Recomenda√ß√µes
1. A√ß√µes imediatas
2. Melhorias de processo
3. Investimentos necess√°rios
```

### 3. Dataset Limpo
- Arquivo Parquet com dados corrigidos
- Metadados de qualidade
- Log de transforma√ß√µes aplicadas

---

## üèÜ Crit√©rios de Avalia√ß√£o

| Crit√©rio | Peso | Descri√ß√£o |
|----------|------|-----------|
| **Implementa√ß√£o T√©cnica** | 40% | C√≥digo PySpark correto e eficiente |
| **An√°lise de Qualidade** | 30% | Identifica√ß√£o precisa dos problemas |
| **KQIs e M√©tricas** | 20% | C√°lculos corretos e relevantes |
| **Documenta√ß√£o** | 10% | Clareza e completude do relat√≥rio |

### N√≠veis de Desempenho:
- ü•á **Excelente (90-100%)**: Implementa√ß√£o completa + insights avan√ßados
- ü•à **Bom (80-89%)**: Implementa√ß√£o correta das funcionalidades principais
- ü•â **Satisfat√≥rio (70-79%)**: Implementa√ß√£o b√°sica com alguns problemas
- ‚ùå **Insuficiente (<70%)**: Implementa√ß√£o incompleta ou incorreta

---

## üí° Dicas de Sucesso

### T√©cnicas:
- Use `cache()` em DataFrames reutilizados
- Prefira `filter()` antes de `groupBy()`
- Utilize `coalesce()` para otimizar parti√ß√µes

### Valida√ß√µes:
- Teste com subconjunto dos dados primeiro
- Valide cada fun√ß√£o individualmente
- Compare resultados com an√°lise manual

### Documenta√ß√£o:
- Explique suas decis√µes de limpeza
- Justifique os thresholds escolhidos
- Documente limita√ß√µes e suposi√ß√µes

---

## üöÄ Desafios Extras (B√¥nus)

Para alunos que desejam ir al√©m:

### üåü N√≠vel Avan√ßado (+10 pontos)
- Implementar Great Expectations para valida√ß√£o
- Criar pipeline automatizado de qualidade
- Integrar com sistema de alertas

### üåü N√≠vel Expert (+15 pontos)
- Usar Delta Lake para versionamento
- Implementar data lineage tracking
- Criar API REST para consulta de qualidade

---

## üìÖ Prazo de Entrega

**Data limite:** [Definir conforme cronograma da turma]

**Formato de entrega:**
- Reposit√≥rio Git com c√≥digo e documenta√ß√£o
- Apresenta√ß√£o de 10 minutos dos resultados
- Demo ao vivo do dashboard implementado

---

## üÜò Suporte

- **D√∫vidas t√©cnicas:** F√≥rum da disciplina
- **Problemas com ambiente:** Slack do curso
- **Office hours:** Ter√ßas 19h-20h

**Boa sorte! üçÄ**

---

*"A qualidade nunca √© um acidente; √© sempre o resultado de um esfor√ßo inteligente."* - John Ruskin